{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac179577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS is available\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "\n",
    "# Check if MPS is built\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())\n",
    "\n",
    "# Check current device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Current device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d763a",
   "metadata": {},
   "source": [
    "<h4> # Import all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35308530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_images, split_data\n",
    "from preprocessing import preprocess_all_images,expand_channels_for_split,get_augmentation_transform,show_random_clahe_images_per_label,preprocess_image_cv2\n",
    "from dataset import MergedImagesDataset\n",
    "from model import get_resnet18_model,get_resnet18_model_layer_added, get_mobilenetv2_model,get_mobilenetv2_model_layer_added,get_efficientnetb0_model_layer_added,get_efficientnetv2_s_model_layer_added\n",
    "from train import train_model_with_val\n",
    "from evaluate import evaluate_model, plot_training_curves\n",
    "from utils import EarlyStoppingWithLR, save_best_model_state\n",
    "from grad_cam import show_grad_cam_for_random_images_per_label\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a067af3",
   "metadata": {},
   "source": [
    "<h4> # 1. Load images and labels <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89960b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images()\n",
    "#labels = ['Good' if l == 'Good' else 'Defective' for l in labels] ## Binary mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aabfd1",
   "metadata": {},
   "source": [
    "<h4> # 2. Preprocess images <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_images, sobel_images, canny_images, clahe_images = preprocess_all_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_clahe_images_per_label(clahe_images, labels, n_per_label=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de699515",
   "metadata": {},
   "source": [
    "<h4> # 3. Split data. <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = split_data(list(clahe_images),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b386c0",
   "metadata": {},
   "source": [
    "<h4> # 4. Expand channels for compatibility with pretrained models <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_exp, x_val_exp, x_test_exp = expand_channels_for_split(x_train, x_val, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fd53c",
   "metadata": {},
   "source": [
    "<h4> # 5. Prepare label mapping <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = sorted(set(labels))\n",
    "label_to_idx = {label: idx for idx , label in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6695d31",
   "metadata": {},
   "source": [
    "<h4> # 6. Data augmentation <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_augmentation_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86901555",
   "metadata": {},
   "source": [
    "<h4> # 7. Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6673879",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MergedImagesDataset(x_train_exp, y_train, label_to_idx, transform=transform)\n",
    "val_dataset = MergedImagesDataset(x_val_exp, y_val, label_to_idx)\n",
    "test_dataset = MergedImagesDataset(x_test_exp, y_test, label_to_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3542c",
   "metadata": {},
   "source": [
    "<h4> # 8. Model, loss, optimizer, scheduler <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "num_classes = len(unique_labels)\n",
    "model = get_efficientnetv2_s_model_layer_added(num_classes, freeze=False).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4, weight_decay=1e-5)\n",
    "early_stopper = EarlyStoppingWithLR(optimizer, patience=4, lr_patience=2, factor=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0fd1d",
   "metadata": {},
   "source": [
    "<h4> # 9. Train <h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57315450",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, acc_history, val_loss_history, val_acc_history = train_model_with_val(\n",
    "    model, train_loader, val_loader, criterion, optimizer, device, num_epochs=50, early_stopper=early_stopper\n",
    ")\n",
    "save_best_model_state(early_stopper.best_state, \"models/best_model_4.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a65c0f",
   "metadata": {},
   "source": [
    "<h4> # 10. Evaluate <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(loss_history, acc_history, val_loss_history, val_acc_history)\n",
    "evaluate_model(model, test_loader, device, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed118bb3",
   "metadata": {},
   "source": [
    "<h4> # 11 Grad-Cam <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM visualization for 2 random images per label (using numpy arrays)\n",
    "num_classes = len(unique_labels)  # or the correct number for your task\n",
    "model = get_efficientnetv2_s_model_layer_added(num_classes, freeze=False)\n",
    "model.load_state_dict(torch.load(\"models/best_model.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "show_grad_cam_for_random_images_per_label(model, test_dataset, labels, label_to_idx, device, n_per_label=2)\n",
    "\n",
    "# Debug model predictions for Scratch images in the test set only if debug is True\n",
    "debug = False\n",
    "if debug:\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    # Find indices of Nick images in the test set\n",
    "    nick_indices_test = [i for i, l in enumerate(y_test) if l == \"Nick\"]\n",
    "\n",
    "    for idx in nick_indices_test:  # Check all Nick images in test set\n",
    "        img_array = x_test_exp[idx]\n",
    "        # Preprocess as in grad-cam\n",
    "        from torchvision import transforms\n",
    "        input_tensor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])(img_array).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            pred_class = torch.argmax(probs).item()\n",
    "            pred_label = unique_labels[pred_class]\n",
    "            print(f\"Test idx: {idx}, True label: Scratch, Predicted class: {pred_class} ({pred_label}), Probabilities: {probs.cpu().numpy()}\")\n",
    "\n",
    "    evaluate_model(model, test_loader, device, unique_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

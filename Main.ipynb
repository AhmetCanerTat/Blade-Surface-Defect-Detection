{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac179577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS is available\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "\n",
    "# Check if MPS is built\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())\n",
    "\n",
    "# Check current device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Current device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d763a",
   "metadata": {},
   "source": [
    "<h4> # Import all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35308530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_images, split_data\n",
    "from preprocessing import preprocess_all_images,expand_channels_for_split,get_augmentation_transform,show_random_clahe_images_per_label,preprocess_image_cv2\n",
    "from dataset import MergedImagesDataset\n",
    "from model import get_resnet18_model,get_resnet18_model_layer_added, get_mobilenetv2_model,get_mobilenetv2_model_layer_added,get_efficientnetb0_model_layer_added,get_efficientnetv2_s_model_layer_added\n",
    "from train import train_model_with_val\n",
    "from evaluate import evaluate_model\n",
    "from utils import EarlyStoppingWithLR, save_best_model_state\n",
    "from grad_cam import show_grad_cam_for_random_images_per_label\n",
    "import mlflow\n",
    "import torch\n",
    "from mlflow_log import log_after_evaluation, log_after_training, log_before_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Blade_Surface_Defect_Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a067af3",
   "metadata": {},
   "source": [
    "<h4> # 1. Load images and labels <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89960b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images()\n",
    "#labels = ['Good' if l == 'Good' else 'Defective' for l in labels] ## Binary mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aabfd1",
   "metadata": {},
   "source": [
    "<h4> # 2. Preprocess images <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_limit = 1.5\n",
    "tile_grid_size = (3,3)\n",
    "\n",
    "clahe_images = preprocess_all_images(images,clip_limit,tile_grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_clahe_images_per_label(clahe_images, labels, n_per_label=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de699515",
   "metadata": {},
   "source": [
    "<h4> # 3. Split data. <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = split_data(list(clahe_images),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b386c0",
   "metadata": {},
   "source": [
    "<h4> # 4. Expand channels for compatibility with pretrained models <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_exp, x_val_exp, x_test_exp = expand_channels_for_split(x_train, x_val, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fd53c",
   "metadata": {},
   "source": [
    "<h4> # 5. Prepare label mapping <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = sorted(set(labels))\n",
    "label_to_idx = {label: idx for idx , label in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6695d31",
   "metadata": {},
   "source": [
    "<h4> # 6. Data augmentation <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_augmentation_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2a1bf",
   "metadata": {},
   "source": [
    "<h4> Parameters <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07899a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "lr_rate=1e-4\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86901555",
   "metadata": {},
   "source": [
    "<h4> # 7. Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6673879",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MergedImagesDataset(x_train_exp, y_train, label_to_idx, transform=transform)\n",
    "val_dataset = MergedImagesDataset(x_val_exp, y_val, label_to_idx)\n",
    "test_dataset = MergedImagesDataset(x_test_exp, y_test, label_to_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3542c",
   "metadata": {},
   "source": [
    "<h4> # 8. Model, loss, optimizer, scheduler <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "num_classes = len(unique_labels)\n",
    "model = get_efficientnetv2_s_model_layer_added(num_classes, freeze=False).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr_rate, weight_decay=1e-5)\n",
    "early_stopper = EarlyStoppingWithLR(optimizer, patience=4, lr_patience=2, factor=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0fd1d",
   "metadata": {},
   "source": [
    "<h4> # 9. Train and Evaluate <h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57315450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Blade Surface Defect Detection_clahe_test5\") as run:\n",
    "\n",
    "    log_before_training(num_epochs, lr_rate, batch_size, criterion, model, clip_limit, tile_grid_size)\n",
    "\n",
    "    loss_history, acc_history, val_loss_history, val_acc_history = train_model_with_val(\n",
    "        model, train_loader, val_loader, criterion, optimizer, device, num_epochs, early_stopper=early_stopper\n",
    "    )\n",
    "    save_best_model_state(early_stopper.best_state, \"models/best_model_4.pth\")\n",
    "    log_after_training(model, test_loader, device, run.info.run_id)\n",
    "    report = evaluate_model(model, test_loader, device, unique_labels)\n",
    "    log_after_evaluation(report, unique_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed118bb3",
   "metadata": {},
   "source": [
    "<h4> # 11 Grad-Cam <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM visualization for 2 random images per label (using numpy arrays)\n",
    "num_classes = len(unique_labels)  # or the correct number for your task\n",
    "model = get_efficientnetv2_s_model_layer_added(num_classes, freeze=False)\n",
    "model.load_state_dict(torch.load(\"models/best_model_4.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "# Get the target layer for ResNet18 (usually the last convolutional layer)\n",
    "  # For ResNet18, this is typically the last conv layer\n",
    "\n",
    "show_grad_cam_for_random_images_per_label(model, test_dataset, y_test, label_to_idx, device, n_per_label=2, )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
